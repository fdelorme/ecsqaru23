---
title: Keynote speakers
image: /ecsqaru23/img/jdavis-headshot.jpg
---

## [Jesse Davis](https://people.cs.kuleuven.be/~jesse.davis/)

Jesse Davis is a Professor in the CS department at KU Leuven, Belgium. His research focuses on developing novel artificial intelligence and machine learning algorithms, with a particular emphasis on analyzing structured data and combining learning and reasoning. Jesse’s passions lie in using these techniques to make sense of lifestyle data, address problems in (elite) athlete monitoring and detecting anomalies. He is particularly well known for his work on sports analytics, which has attracted significant interest from practitioners and the media. Prior to joining KU Leuven, he obtained his bachelor’s degree from Williams College, his PhD from the University of Wisconsin, and completed a post-doc at the University of Washington.

Jesse co-founded and serves on the board of directors of the KU Leuven spinoff runeasi. This company offers a wearable solution that provided real-time biomechanical feedback about an individual’s running pattern.


### Reasoning about Tree Ensembles 

Abstract: Tree ensembles such as (gradient) boosted trees and random forests are a popular class of models that are often used in practice. Unfortunately, merely achieving good predictive performance is insufficient for a deployed model because it is important to assess other factors such as a model's robustness and explainability. However, like other expressive model classes (e.g., neural networks), it is challenging to learn robust models where decisions can be explained. For example, it is often possible to flip an example's predicted label by applying a tiny, specifically constructed perturbation. This type of behavior is undesirable because it degrades a model’s performance and erodes a user’s trust in the model. This talk will argue that the solution to this problem is to develop techniques that are able to reason about a learned model’s behavior. Moreover, I will advocate that using such approaches is a key part of evaluating learning pipelines because it can help debug learned models and the data used to train them. I will present two approaches for gaining insight into how a model will behavior. First, I will discuss a generic approach for verifying whether a learned tree ensemble exhibits a wide range of behaviors.  Second, I will describe an approach that identifies whether the tree ensemble is at a heightened risk of making a misprediction in a post-deployment setting. Throughout the talk I will use several illustrative examples from real-world applications, with an emphasis on applications in professional soccer. 

